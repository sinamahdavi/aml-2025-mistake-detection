{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinamahdavi/aml-2025-mistake-detection/blob/step2/notebooks/colab_compare_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a882e3f",
      "metadata": {
        "id": "6a882e3f"
      },
      "source": [
        "# Colab Quickstart"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf code\n",
        "\n",
        "!git clone --recursive -b step2 https://github.com/sinamahdavi/aml-2025-mistake-detection.git code\n",
        "%cd code"
      ],
      "metadata": {
        "id": "UiUFeWTG1jnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819220d2-09a1-49bd-fff6-d2a4012f8b4e"
      },
      "id": "UiUFeWTG1jnB",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'code'...\n",
            "remote: Enumerating objects: 547, done.\u001b[K\n",
            "remote: Counting objects: 100% (547/547), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 547 (delta 359), reused 498 (delta 318), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (547/547), 255.62 KiB | 2.01 MiB/s, done.\n",
            "Resolving deltas: 100% (359/359), done.\n",
            "Submodule 'annotations' (https://github.com/CaptainCook4D/annotations) registered for path 'annotations'\n",
            "Cloning into '/content/code/annotations'...\n",
            "remote: Enumerating objects: 152, done.        \n",
            "remote: Counting objects: 100% (152/152), done.        \n",
            "remote: Compressing objects: 100% (98/98), done.        \n",
            "remote: Total 152 (delta 75), reused 108 (delta 46), pack-reused 0 (from 0)        \n",
            "Receiving objects: 100% (152/152), 793.14 KiB | 3.22 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Submodule path 'annotations': checked out '0e9a108be2cbcbcbd592e7418c0ab9c16232d27a'\n",
            "/content/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NXArnjm51vZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0260298f-1e6c-480b-b705-331f28c4587c"
      },
      "id": "NXArnjm51vZx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data and checkpoints\n",
        "# TODO: Update paths below with your own Google Drive paths\n",
        "\n",
        "import os\n",
        "os.chdir('/content/code')\n",
        "\n",
        "# Create directories\n",
        "!mkdir -p data/video/omnivore\n",
        "!mkdir -p checkpoints\n",
        "\n",
        "# Extract features (update path to your omnivore features zip)\n",
        "print(\"Extracting features...\")\n",
        "if os.path.exists(\"/content/drive/MyDrive/AML/data/features/omnivore.zip\"):\n",
        "    # Extract to data/video/omnivore\n",
        "    !unzip -q \"/content/drive/MyDrive/AML/data/features/omnivore.zip\" -d data/video/ 2>&1\n",
        "\n",
        "    # If files were extracted to data/video/omnivore/omnivore/, move them up\n",
        "    if os.path.exists(\"data/video/omnivore/omnivore\"):\n",
        "        !mv data/video/omnivore/omnivore/* data/video/omnivore/ 2>/dev/null || true\n",
        "        !rmdir data/video/omnivore/omnivore 2>/dev/null || true\n",
        "\n",
        "    # Verify extraction\n",
        "    if os.path.exists(\"data/video/omnivore\"):\n",
        "        num_files = len([f for f in os.listdir(\"data/video/omnivore\") if f.endswith('.npz')])\n",
        "        print(f\"âœ… Extracted {num_files} feature files to data/video/omnivore/\")\n",
        "    else:\n",
        "        print(\"âš ï¸  Extraction may have failed. Check the zip structure.\")\n",
        "else:\n",
        "    print(\"âš ï¸  Features zip not found. Please update the path.\")\n",
        "    print(\"   Expected: /content/drive/MyDrive/AML/data/features/omnivore.zip\")\n",
        "\n",
        "# Extract checkpoints if needed (optional)\n",
        "# if os.path.exists(\"/content/drive/MyDrive/AML/code/error_recognition_best.zip\"):\n",
        "#     !unzip -q \"/content/drive/MyDrive/AML/code/error_recognition_best.zip\" -d checkpoints/ 2>&1\n",
        "#     print(\"âœ… Checkpoints extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1XpBa6wPyq0",
        "outputId": "7546ff17-0259-4ba6-8ed9-3262b36342ef"
      },
      "id": "Q1XpBa6wPyq0",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n",
            "âœ… Extracted 384 feature files to data/video/omnivore/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval tabulate\n",
        "!pip install loguru"
      ],
      "metadata": {
        "id": "lx6FtK902Vv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed6add7-7394-45d0-9a63-bf25425669fd"
      },
      "id": "lx6FtK902Vv2",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from torcheval) (4.15.0)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify annotations submodule and check CUDA availability\n",
        "import os\n",
        "import torch\n",
        "os.chdir('/content/code')\n",
        "\n",
        "# Check CUDA availability\n",
        "print(\"=\" * 60)\n",
        "print(\"DEVICE CHECK\")\n",
        "print(\"=\" * 60)\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"âš ï¸  CUDA not available - will use CPU\")\n",
        "    print(\"   Note: Enable GPU in Colab: Runtime â†’ Change runtime type â†’ GPU\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if annotations directory is properly initialized\n",
        "if not os.path.exists('annotations/annotation_json/error_annotations.json'):\n",
        "    print(\"\\nğŸ“¦ Initializing annotations submodule...\")\n",
        "    !git submodule update --init --recursive\n",
        "    print(\"âœ… Annotations submodule initialized\")\n",
        "else:\n",
        "    print(\"\\nâœ… Annotations already initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN8rOCz5kNEl",
        "outputId": "18d128bb-6a36-4c88-a85e-14bbbdf7deac"
      },
      "id": "NN8rOCz5kNEl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DEVICE CHECK\n",
            "============================================================\n",
            "âœ… CUDA available: Tesla T4\n",
            "   CUDA Version: 12.6\n",
            "============================================================\n",
            "\n",
            "âœ… Annotations already initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train MLP model for error recognition\n",
        "import os\n",
        "os.chdir('/content/code')\n",
        "\n",
        "!python train_er.py \\\n",
        "    --variant MLP \\\n",
        "    --backbone omnivore \\\n",
        "    --split recordings \\\n",
        "    --batch_size 8 \\\n",
        "    --num_epochs 10 \\\n",
        "    --lr 1e-3 \\\n",
        "    --weight_decay 1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBx4-re-S4VP",
        "outputId": "ae7fe39e-7209-47db-d236-16d7a9c8e590"
      },
      "id": "NBx4-re-S4VP",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------\n",
            "Training step model and testing on step level\n",
            "Train args: {'num_workers': 8, 'pin_memory': False, 'shuffle': True, 'batch_size': 8}\n",
            "Test args: {'num_workers': 8, 'pin_memory': False, 'shuffle': False, 'batch_size': 1}\n",
            "{'batch_size': 8, 'test_batch_size': 1, 'num_epochs': 10, 'lr': 0.001, 'weight_decay': 0.001, 'ckpt': None, 'seed': 42, 'backbone': 'omnivore', 'ckpt_directory': './checkpoints', 'split': 'recordings', 'variant': 'MLP', 'model_name': None, 'task_name': 'error_recognition', 'error_category': None, 'modality': ['video'], 'device': None}\n",
            "-------------------------------------------------------------\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Train Epoch: 1, Progress: 496/497, Loss: 0.821538: 100% 497/497 [00:19<00:00, 25.93it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 139.65it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3918058870326173, 'recall': 0.243691241959426, 'f1': 0.3004881025015253, 'accuracy': 0.6309747331151763, 'auc': np.float64(0.5913067935219969), 'pr_auc': tensor(0.3415)}\n",
            "val Step Level Metrics: {'precision': 0.3858520900321543, 'recall': 0.5106382978723404, 'f1': 0.43956043956043955, 'accuracy': 0.5506607929515418, 'auc': np.float64(0.5500524759087874), 'pr_auc': tensor(0.3659)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 163.39it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4279481755684823, 'recall': 0.25676211628460377, 'f1': 0.3209558276733925, 'accuracy': 0.6427490871152843, 'auc': np.float64(0.5941417685804092), 'pr_auc': tensor(0.3543)}\n",
            "test Step Level Metrics: {'precision': 0.40764331210191085, 'recall': 0.5311203319502075, 'f1': 0.46126126126126127, 'accuracy': 0.5543964232488823, 'auc': np.float64(0.5645855447264305), 'pr_auc': tensor(0.3849)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 1, Train Loss: 1.025237, Test Loss: 1.088345, Precision: 0.385852, Recall: 0.510638, F1: 0.439560, AUC: 0.550052\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 2, Progress: 496/497, Loss: 0.855626: 100% 497/497 [00:18<00:00, 27.34it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:05<00:00, 131.65it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3728329205562964, 'recall': 0.16138875144317993, 'f1': 0.22526618705035972, 'accuracy': 0.6389410439354112, 'auc': np.float64(0.5549502294860346), 'pr_auc': tensor(0.3329)}\n",
            "val Step Level Metrics: {'precision': 0.4206008583690987, 'recall': 0.41702127659574467, 'f1': 0.4188034188034188, 'accuracy': 0.6005873715124816, 'auc': np.float64(0.5676462169640302), 'pr_auc': tensor(0.3766)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:03<00:00, 167.87it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4264188849824209, 'recall': 0.20203061791068455, 'f1': 0.27416576964477934, 'accuracy': 0.6482524778299427, 'auc': np.float64(0.6017800001319911), 'pr_auc': tensor(0.3485)}\n",
            "test Step Level Metrics: {'precision': 0.35947712418300654, 'recall': 0.45643153526970953, 'f1': 0.40219378427787933, 'accuracy': 0.5126676602086438, 'auc': np.float64(0.5216587860658111), 'pr_auc': tensor(0.3593)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 2, Train Loss: 0.985407, Test Loss: 1.109652, Precision: 0.420601, Recall: 0.417021, F1: 0.418803, AUC: 0.567646\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 3, Progress: 496/497, Loss: 0.448313: 100% 497/497 [00:18<00:00, 27.37it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:05<00:00, 125.53it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3848454636091725, 'recall': 0.4774863928748144, 'f1': 0.4261896875345037, 'accuracy': 0.5818089158306958, 'auc': np.float64(0.5929988525894967), 'pr_auc': tensor(0.3537)}\n",
            "val Step Level Metrics: {'precision': 0.3761755485893417, 'recall': 0.5106382978723404, 'f1': 0.4332129963898917, 'accuracy': 0.5389133627019089, 'auc': np.float64(0.5496803740101136), 'pr_auc': tensor(0.3610)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:03<00:00, 170.92it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.43556684248225563, 'recall': 0.5305782501784723, 'f1': 0.4784008010298956, 'accuracy': 0.6195618153364633, 'auc': np.float64(0.6393723032054182), 'pr_auc': tensor(0.3855)}\n",
            "test Step Level Metrics: {'precision': 0.3592814371257485, 'recall': 0.4979253112033195, 'f1': 0.41739130434782606, 'accuracy': 0.5007451564828614, 'auc': np.float64(0.5385168387532567), 'pr_auc': tensor(0.3592)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 3, Train Loss: 0.962941, Test Loss: 1.066287, Precision: 0.376176, Recall: 0.510638, F1: 0.433213, AUC: 0.549680\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 4, Progress: 496/497, Loss: 0.485103: 100% 497/497 [00:17<00:00, 27.79it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 138.11it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.4506447309915518, 'recall': 0.16716147121886854, 'f1': 0.24386429258902792, 'accuracy': 0.6628399763961161, 'auc': np.float64(0.5978953805574672), 'pr_auc': tensor(0.3462)}\n",
            "val Step Level Metrics: {'precision': 0.42452830188679247, 'recall': 0.3829787234042553, 'f1': 0.40268456375838924, 'accuracy': 0.6079295154185022, 'auc': np.float64(0.5787806507012689), 'pr_auc': tensor(0.3755)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 149.51it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.47250996015936253, 'recall': 0.18814944078686444, 'f1': 0.2691325807000624, 'accuracy': 0.663980177360459, 'auc': np.float64(0.6202199653999112), 'pr_auc': tensor(0.3559)}\n",
            "test Step Level Metrics: {'precision': 0.4125874125874126, 'recall': 0.4896265560165975, 'f1': 0.4478178368121442, 'accuracy': 0.5663189269746647, 'auc': np.float64(0.5934912670076232), 'pr_auc': tensor(0.3853)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 4, Train Loss: 0.941501, Test Loss: 1.251308, Precision: 0.424528, Recall: 0.382979, F1: 0.402685, AUC: 0.578781\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 5, Progress: 496/497, Loss: 0.922730: 100% 497/497 [00:17<00:00, 27.76it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:03<00:00, 174.79it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3662916486369537, 'recall': 0.5584694045851889, 'f1': 0.4424119683804795, 'accuracy': 0.5421382973016469, 'auc': np.float64(0.5725949884693782), 'pr_auc': tensor(0.3482)}\n",
            "val Step Level Metrics: {'precision': 0.35585585585585583, 'recall': 0.33617021276595743, 'f1': 0.34573304157549234, 'accuracy': 0.5609397944199707, 'auc': np.float64(0.5193874630283369), 'pr_auc': tensor(0.3487)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 117.94it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.39842511632663496, 'recall': 0.618069326564607, 'f1': 0.48451685113791815, 'accuracy': 0.5675534689619197, 'auc': np.float64(0.6211162962277583), 'pr_auc': tensor(0.3718)}\n",
            "test Step Level Metrics: {'precision': 0.39299610894941633, 'recall': 0.4190871369294606, 'f1': 0.40562248995983935, 'accuracy': 0.5588673621460507, 'auc': np.float64(0.5566679532953779), 'pr_auc': tensor(0.3733)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 5, Train Loss: 0.939612, Test Loss: 1.047180, Precision: 0.355856, Recall: 0.336170, F1: 0.345733, AUC: 0.519387\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 6, Progress: 496/497, Loss: 0.724242: 100% 497/497 [00:17<00:00, 28.05it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:03<00:00, 177.48it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.40185581727337616, 'recall': 0.2785749628896586, 'f1': 0.32904734073641145, 'accuracy': 0.6304919263987984, 'auc': np.float64(0.593660645810289), 'pr_auc': tensor(0.3466)}\n",
            "val Step Level Metrics: {'precision': 0.352112676056338, 'recall': 0.2127659574468085, 'f1': 0.26525198938992045, 'accuracy': 0.593245227606461, 'auc': np.float64(0.5366758897051809), 'pr_auc': tensor(0.3466)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 118.21it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4401321222130471, 'recall': 0.33822479574839376, 'f1': 0.3825072886297376, 'accuracy': 0.6409233176838811, 'auc': np.float64(0.6171569499772809), 'pr_auc': tensor(0.3665)}\n",
            "test Step Level Metrics: {'precision': 0.3958333333333333, 'recall': 0.3941908713692946, 'f1': 0.39501039501039503, 'accuracy': 0.5663189269746647, 'auc': np.float64(0.5578162694200521), 'pr_auc': tensor(0.3736)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 6, Train Loss: 0.913413, Test Loss: 1.175332, Precision: 0.352113, Recall: 0.212766, F1: 0.265252, AUC: 0.536676\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 7, Progress: 496/497, Loss: 0.658434: 100% 497/497 [00:17<00:00, 28.05it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:03<00:00, 175.27it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3773267732677327, 'recall': 0.7589477156523173, 'f1': 0.5040530178551867, 'accuracy': 0.5142427981331473, 'auc': np.float64(0.6125177965857882), 'pr_auc': tensor(0.3648)}\n",
            "val Step Level Metrics: {'precision': 0.3128491620111732, 'recall': 0.23829787234042554, 'f1': 0.27053140096618356, 'accuracy': 0.5565345080763583, 'auc': np.float64(0.524320198454346), 'pr_auc': tensor(0.3374)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 156.71it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.373114934834823, 'recall': 0.7516459110018244, 'f1': 0.4986843490158931, 'accuracy': 0.5030777256129368, 'auc': np.float64(0.5996829560752983), 'pr_auc': tensor(0.3621)}\n",
            "test Step Level Metrics: {'precision': 0.36538461538461536, 'recall': 0.3153526970954357, 'f1': 0.33853006681514475, 'accuracy': 0.5573770491803278, 'auc': np.float64(0.5075605519637171), 'pr_auc': tensor(0.3611)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 7, Train Loss: 0.893781, Test Loss: 1.081759, Precision: 0.312849, Recall: 0.238298, F1: 0.270531, AUC: 0.524320\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 8, Progress: 496/497, Loss: 1.467474: 100% 497/497 [00:19<00:00, 25.96it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:03<00:00, 175.64it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.4118898116264938, 'recall': 0.33539501896750784, 'f1': 0.36972727272727274, 'accuracy': 0.628077892816909, 'auc': np.float64(0.5836134131136503), 'pr_auc': tensor(0.3543)}\n",
            "val Step Level Metrics: {'precision': 0.38414634146341464, 'recall': 0.2680851063829787, 'f1': 0.3157894736842105, 'accuracy': 0.5991189427312775, 'auc': np.float64(0.5638393283083676), 'pr_auc': tensor(0.3556)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:03<00:00, 170.02it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.43146006011476457, 'recall': 0.37574363448877607, 'f1': 0.4016789620961587, 'accuracy': 0.631924882629108, 'auc': np.float64(0.6132160445597846), 'pr_auc': tensor(0.3674)}\n",
            "test Step Level Metrics: {'precision': 0.3774193548387097, 'recall': 0.4854771784232365, 'f1': 0.4246823956442831, 'accuracy': 0.5275707898658718, 'auc': np.float64(0.5494113673646627), 'pr_auc': tensor(0.3680)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 8, Train Loss: 0.888219, Test Loss: 1.246333, Precision: 0.384146, Recall: 0.268085, F1: 0.315789, AUC: 0.563839\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 9, Progress: 496/497, Loss: 1.314292: 100% 497/497 [00:19<00:00, 25.72it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 166.39it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3930159070215843, 'recall': 0.6051459673428996, 'f1': 0.47653992271974543, 'accuracy': 0.5675929402929027, 'auc': np.float64(0.6104153788097715), 'pr_auc': tensor(0.3663)}\n",
            "val Step Level Metrics: {'precision': 0.35772357723577236, 'recall': 0.18723404255319148, 'f1': 0.24581005586592178, 'accuracy': 0.6035242290748899, 'auc': np.float64(0.5558725312470184), 'pr_auc': tensor(0.3474)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:03<00:00, 169.27it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.40854027861901876, 'recall': 0.6420242722297137, 'f1': 0.49933680866158736, 'accuracy': 0.5766562336984872, 'auc': np.float64(0.6287734386878798), 'pr_auc': tensor(0.3800)}\n",
            "test Step Level Metrics: {'precision': 0.39941690962099125, 'recall': 0.5684647302904564, 'f1': 0.4691780821917808, 'accuracy': 0.5380029806259314, 'auc': np.float64(0.5724355881501496), 'pr_auc': tensor(0.3820)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 9, Train Loss: 0.869242, Test Loss: 1.083511, Precision: 0.357724, Recall: 0.187234, F1: 0.245810, AUC: 0.555873\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 10, Progress: 496/497, Loss: 0.754870: 100% 497/497 [00:18<00:00, 27.06it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 141.01it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3780239984517128, 'recall': 0.644317994392215, 'f1': 0.47648960175641886, 'accuracy': 0.5395096829569229, 'auc': np.float64(0.601622599373772), 'pr_auc': tensor(0.3593)}\n",
            "val Step Level Metrics: {'precision': 0.41134751773049644, 'recall': 0.24680851063829787, 'f1': 0.30851063829787234, 'accuracy': 0.618208516886931, 'auc': np.float64(0.5874821104856407), 'pr_auc': tensor(0.3614)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:03<00:00, 170.08it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.39467091778638125, 'recall': 0.6873165701594353, 'f1': 0.5014177420288177, 'accuracy': 0.550547730829421, 'auc': np.float64(0.6156069228301861), 'pr_auc': tensor(0.3741)}\n",
            "test Step Level Metrics: {'precision': 0.4351145038167939, 'recall': 0.4730290456431535, 'f1': 0.4532803180914513, 'accuracy': 0.5901639344262295, 'auc': np.float64(0.6069526198977131), 'pr_auc': tensor(0.3951)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 10, Train Loss: 0.850301, Test Loss: 1.089298, Precision: 0.411348, Recall: 0.246809, F1: 0.308511, AUC: 0.587482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Transformer model for error recognition\n",
        "import os\n",
        "os.chdir('/content/code')\n",
        "\n",
        "!python train_er.py \\\n",
        "    --variant Transformer \\\n",
        "    --backbone omnivore \\\n",
        "    --split recordings \\\n",
        "    --batch_size 8 \\\n",
        "    --num_epochs 10 \\\n",
        "    --lr 1e-3 \\\n",
        "    --weight_decay 1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV-3n_FbUKFb",
        "outputId": "cd480050-562a-4f45-96ac-9216f2e948ef"
      },
      "id": "aV-3n_FbUKFb",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------\n",
            "Training step model and testing on step level\n",
            "Train args: {'num_workers': 8, 'pin_memory': False, 'shuffle': True, 'batch_size': 8}\n",
            "Test args: {'num_workers': 8, 'pin_memory': False, 'shuffle': False, 'batch_size': 1}\n",
            "{'batch_size': 8, 'test_batch_size': 1, 'num_epochs': 10, 'lr': 0.001, 'weight_decay': 0.001, 'ckpt': None, 'seed': 42, 'backbone': 'omnivore', 'ckpt_directory': './checkpoints', 'split': 'recordings', 'variant': 'Transformer', 'model_name': None, 'task_name': 'error_recognition', 'error_category': None, 'modality': ['video'], 'device': None}\n",
            "-------------------------------------------------------------\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Train Epoch: 1, Progress: 496/497, Loss: 0.759699: 100% 497/497 [00:20<00:00, 23.79it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 157.48it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.6746955635427284, 'auc': np.float64(0.5193759569676608), 'pr_auc': tensor(0.3253)}\n",
            "val Step Level Metrics: {'precision': 0.3443396226415094, 'recall': 0.31063829787234043, 'f1': 0.32662192393736017, 'accuracy': 0.5580029368575624, 'auc': np.float64(0.5246636771300448), 'pr_auc': tensor(0.3449)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 139.10it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.6711789254042775, 'auc': np.float64(0.4591225022176855), 'pr_auc': tensor(0.3288)}\n",
            "test Step Level Metrics: {'precision': 0.3411764705882353, 'recall': 0.12033195020746888, 'f1': 0.17791411042944785, 'accuracy': 0.6005961251862891, 'auc': np.float64(0.5051095242690341), 'pr_auc': tensor(0.3570)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 1, Train Loss: 1.073177, Test Loss: 1.131145, Precision: 0.344340, Recall: 0.310638, F1: 0.326622, AUC: 0.524664\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 2, Progress: 496/497, Loss: 0.357608: 100% 497/497 [00:20<00:00, 24.06it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 157.08it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.674749208733437, 'auc': np.float64(0.5053152314384236), 'pr_auc': tensor(0.3253)}\n",
            "val Step Level Metrics: {'precision': 0.37209302325581395, 'recall': 0.13617021276595745, 'f1': 0.19937694704049844, 'accuracy': 0.6226138032305433, 'auc': np.float64(0.48344623604617887), 'pr_auc': tensor(0.3488)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 148.19it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.6711789254042775, 'auc': np.float64(0.5242913610182726), 'pr_auc': tensor(0.3288)}\n",
            "test Step Level Metrics: {'precision': 0.35507246376811596, 'recall': 0.2033195020746888, 'f1': 0.25857519788918204, 'accuracy': 0.5812220566318927, 'auc': np.float64(0.5055920100357039), 'pr_auc': tensor(0.3583)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 2, Train Loss: 1.035959, Test Loss: 1.297663, Precision: 0.372093, Recall: 0.136170, F1: 0.199377, AUC: 0.483446\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 3, Progress: 496/497, Loss: 0.872863: 100% 497/497 [00:20<00:00, 24.39it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 157.49it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.32570768031398695, 'recall': 0.9991753257463302, 'f1': 0.49127217435377596, 'accuracy': 0.32694061477388553, 'auc': np.float64(0.5342287398938065), 'pr_auc': tensor(0.3257)}\n",
            "val Step Level Metrics: {'precision': 0.36524822695035464, 'recall': 0.43829787234042555, 'f1': 0.3984526112185687, 'accuracy': 0.5433186490455213, 'auc': np.float64(0.5307413414750501), 'pr_auc': tensor(0.3539)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 142.09it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.3291371142924442, 'recall': 0.9975410486237805, 'f1': 0.49496221662468515, 'accuracy': 0.3306207616066771, 'auc': np.float64(0.5571434236994977), 'pr_auc': tensor(0.3291)}\n",
            "test Step Level Metrics: {'precision': 0.36893203883495146, 'recall': 0.3153526970954357, 'f1': 0.3400447427293065, 'accuracy': 0.5603576751117735, 'auc': np.float64(0.5232509890958217), 'pr_auc': tensor(0.3622)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 3, Train Loss: 1.008070, Test Loss: 1.056063, Precision: 0.365248, Recall: 0.438298, F1: 0.398453, AUC: 0.530741\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 4, Progress: 496/497, Loss: 0.691201: 100% 497/497 [00:20<00:00, 24.56it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 155.04it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.32860520094562645, 'recall': 0.08024080488207158, 'f1': 0.12898521906276927, 'accuracy': 0.6475242744487957, 'auc': np.float64(0.5379835041283674), 'pr_auc': tensor(0.3255)}\n",
            "val Step Level Metrics: {'precision': 0.3342618384401114, 'recall': 0.5106382978723404, 'f1': 0.40404040404040403, 'accuracy': 0.4801762114537445, 'auc': np.float64(0.5061730750882548), 'pr_auc': tensor(0.3396)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:04<00:00, 137.74it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.39369806094182824, 'recall': 0.0901879907987626, 'f1': 0.14675701839303001, 'accuracy': 0.6551643192488263, 'auc': np.float64(0.5667016025794369), 'pr_auc': tensor(0.3347)}\n",
            "test Step Level Metrics: {'precision': 0.36394557823129253, 'recall': 0.44398340248962653, 'f1': 0.4, 'accuracy': 0.5216095380029806, 'auc': np.float64(0.5053604168677024), 'pr_auc': tensor(0.3613)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 4, Train Loss: 1.004404, Test Loss: 1.066852, Precision: 0.334262, Recall: 0.510638, F1: 0.404040, AUC: 0.506173\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 5, Progress: 496/497, Loss: 0.763475: 100% 497/497 [00:20<00:00, 24.55it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 156.54it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3540193983231958, 'recall': 0.35518720105558305, 'f1': 0.35460233821834347, 'accuracy': 0.5794753500348694, 'auc': np.float64(0.5460809260752243), 'pr_auc': tensor(0.3355)}\n",
            "val Step Level Metrics: {'precision': 0.33884297520661155, 'recall': 0.34893617021276596, 'f1': 0.3438155136268344, 'accuracy': 0.540381791483113, 'auc': np.float64(0.543411888178609), 'pr_auc': tensor(0.3429)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 123.54it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.3662062319306136, 'recall': 0.36170381534068374, 'f1': 0.363941099006345, 'accuracy': 0.5842723004694835, 'auc': np.float64(0.5535081752813181), 'pr_auc': tensor(0.3423)}\n",
            "test Step Level Metrics: {'precision': 0.4061302681992337, 'recall': 0.43983402489626555, 'f1': 0.42231075697211157, 'accuracy': 0.5678092399403875, 'auc': np.float64(0.5657386857087716), 'pr_auc': tensor(0.3798)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 5, Train Loss: 0.996255, Test Loss: 1.066379, Precision: 0.338843, Recall: 0.348936, F1: 0.343816, AUC: 0.543412\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 6, Progress: 496/497, Loss: 0.760491: 100% 497/497 [00:19<00:00, 25.42it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 154.38it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.32534292540198106, 'recall': 0.9995051954477981, 'f1': 0.4908969399947346, 'accuracy': 0.3257067753875865, 'auc': np.float64(0.5278857029283895), 'pr_auc': tensor(0.3253)}\n",
            "val Step Level Metrics: {'precision': 0.32083333333333336, 'recall': 0.3276595744680851, 'f1': 0.32421052631578945, 'accuracy': 0.5286343612334802, 'auc': np.float64(0.5118118500143117), 'pr_auc': tensor(0.3371)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 114.41it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.3288457524525151, 'recall': 0.9997620369635917, 'f1': 0.4949052714243644, 'accuracy': 0.3289775691184142, 'auc': np.float64(0.5369023739466112), 'pr_auc': tensor(0.3288)}\n",
            "test Step Level Metrics: {'precision': 0.37606837606837606, 'recall': 0.3651452282157676, 'f1': 0.3705263157894737, 'accuracy': 0.5543964232488823, 'auc': np.float64(0.5104072179870693), 'pr_auc': tensor(0.3653)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 6, Train Loss: 0.996930, Test Loss: 1.058308, Precision: 0.320833, Recall: 0.327660, F1: 0.324211, AUC: 0.511812\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 7, Progress: 496/497, Loss: 1.367899: 100% 497/497 [00:18<00:00, 26.18it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 155.88it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.32551138349057873, 'recall': 0.9986805211941283, 'f1': 0.4909890733645523, 'accuracy': 0.3265114532482163, 'auc': np.float64(0.5400632430345841), 'pr_auc': tensor(0.3255)}\n",
            "val Step Level Metrics: {'precision': 0.33878887070376434, 'recall': 0.8808510638297873, 'f1': 0.48936170212765956, 'accuracy': 0.3656387665198238, 'auc': np.float64(0.46322869955156953), 'pr_auc': tensor(0.3395)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 112.78it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.32922843621721964, 'recall': 0.9988101848179582, 'f1': 0.4952216148188933, 'accuracy': 0.3304642670839854, 'auc': np.float64(0.5299193059665126), 'pr_auc': tensor(0.3292)}\n",
            "test Step Level Metrics: {'precision': 0.36585365853658536, 'recall': 0.9336099585062241, 'f1': 0.5257009345794392, 'accuracy': 0.3949329359165425, 'auc': np.float64(0.521369294605809), 'pr_auc': tensor(0.3654)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 7, Train Loss: 0.999228, Test Loss: 1.052959, Precision: 0.338789, Recall: 0.880851, F1: 0.489362, AUC: 0.463229\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 8, Progress: 496/497, Loss: 0.713302: 100% 497/497 [00:18<00:00, 26.40it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 148.64it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.32700801072157415, 'recall': 0.8853702787398977, 'f1': 0.47761194029850745, 'accuracy': 0.3700713481036425, 'auc': np.float64(0.532285431534636), 'pr_auc': tensor(0.3268)}\n",
            "val Step Level Metrics: {'precision': 0.3380035026269702, 'recall': 0.8212765957446808, 'f1': 0.47890818858560796, 'accuracy': 0.3832599118942731, 'auc': np.float64(0.4939509588779697), 'pr_auc': tensor(0.3393)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 113.73it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.32907893189036586, 'recall': 0.8876021258031253, 'f1': 0.48014417197657205, 'accuracy': 0.3679968701095462, 'auc': np.float64(0.5216791218554554), 'pr_auc': tensor(0.3290)}\n",
            "test Step Level Metrics: {'precision': 0.3624161073825503, 'recall': 0.8962655601659751, 'f1': 0.5161290322580645, 'accuracy': 0.39642324888226527, 'auc': np.float64(0.5041156035896941), 'pr_auc': tensor(0.3621)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 8, Train Loss: 0.996837, Test Loss: 1.062162, Precision: 0.338004, Recall: 0.821277, F1: 0.478908, AUC: 0.493951\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 9, Progress: 496/497, Loss: 0.676128: 100% 497/497 [00:19<00:00, 26.08it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:04<00:00, 149.37it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3199608610567515, 'recall': 0.026966848095002473, 'f1': 0.049741405536963795, 'accuracy': 0.6648784936430449, 'auc': np.float64(0.48618977468441227), 'pr_auc': tensor(0.3251)}\n",
            "val Step Level Metrics: {'precision': 0.3, 'recall': 0.03829787234042553, 'f1': 0.06792452830188679, 'accuracy': 0.6372980910425844, 'auc': np.float64(0.4935979391279458), 'pr_auc': tensor(0.3434)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:06<00:00, 111.25it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.35917312661498707, 'recall': 0.033076862060759896, 'f1': 0.060575246949448, 'accuracy': 0.6626499739175795, 'auc': np.float64(0.5438971660735119), 'pr_auc': tensor(0.3298)}\n",
            "test Step Level Metrics: {'precision': 0.35294117647058826, 'recall': 0.04979253112033195, 'f1': 0.08727272727272728, 'accuracy': 0.6259314456035767, 'auc': np.float64(0.48304062530155356), 'pr_auc': tensor(0.3589)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 9, Train Loss: 0.999405, Test Loss: 1.070388, Precision: 0.300000, Recall: 0.038298, F1: 0.067925, AUC: 0.493598\n",
            "  0% 0/497 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Train Epoch: 10, Progress: 496/497, Loss: 0.701483: 100% 497/497 [00:18<00:00, 26.23it/s]\n",
            "val Progress: 37282/681: 100% 681/681 [00:05<00:00, 135.32it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.325232692256109, 'recall': 0.999917532574633, 'f1': 0.4908211387050418, 'accuracy': 0.3252239686712086, 'auc': np.float64(0.5292807337106772), 'pr_auc': tensor(0.3252)}\n",
            "val Step Level Metrics: {'precision': 0.37850467289719625, 'recall': 0.3446808510638298, 'f1': 0.36080178173719374, 'accuracy': 0.57856093979442, 'auc': np.float64(0.5389562064688483), 'pr_auc': tensor(0.3566)}\n",
            "----------------------------------------------------------------\n",
            "  0% 0/671 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "test Progress: 38340/671: 100% 671/671 [00:05<00:00, 124.44it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.32882965126894287, 'recall': 1.0, 'f1': 0.49491618576532015, 'accuracy': 0.3288471570161711, 'auc': np.float64(0.5466698967382092), 'pr_auc': tensor(0.3288)}\n",
            "test Step Level Metrics: {'precision': 0.34098360655737703, 'recall': 0.4315352697095436, 'f1': 0.38095238095238093, 'accuracy': 0.496274217585693, 'auc': np.float64(0.4612901669400753), 'pr_auc': tensor(0.3513)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 10, Train Loss: 1.000621, Test Loss: 1.064324, Precision: 0.378505, Recall: 0.344681, F1: 0.360802, AUC: 0.538956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LSTM model for error recognition\n",
        "import os\n",
        "os.chdir('/content/code')\n",
        "\n",
        "!python train_lstm.py \\\n",
        "    --variant LSTM \\\n",
        "    --backbone omnivore \\\n",
        "    --split recordings \\\n",
        "    --batch_size 8 \\\n",
        "    --num_epochs 10 \\\n",
        "    --lr 1e-3 \\\n",
        "    --weight_decay 1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBhNdO7zl-xQ",
        "outputId": "252f08ea-6e70-457d-84bb-a8b9f43e934e"
      },
      "id": "RBhNdO7zl-xQ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training LSTM model for Error Recognition (Step 2b)\n",
            "Backbone: omnivore\n",
            "Split: recordings\n",
            "Learning Rate: 0.001\n",
            "Epochs: 10\n",
            "Device: cuda\n",
            "============================================================\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "Train Epoch: 1, Progress: 496/497, Loss: 0.717343: 100% 497/497 [00:34<00:00, 14.26it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.32it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3494809688581315, 'recall': 0.8595744680851064, 'f1': 0.4969249692496925, 'accuracy': 0.39941262848751835, 'auc': np.float64(0.5154422287949624), 'pr_auc': tensor(0.3489)}\n",
            "val Step Level Metrics: {'precision': 0.07894736842105263, 'recall': 0.42857142857142855, 'f1': 0.13333333333333333, 'accuracy': 0.5465116279069767, 'auc': np.float64(0.3996383363471971), 'pr_auc': tensor(0.0803)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:04<00:00, 16.94it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.3574007220216607, 'recall': 0.8215767634854771, 'f1': 0.4981132075471698, 'accuracy': 0.40536512667660207, 'auc': np.float64(0.5195117244041301), 'pr_auc': tensor(0.3577)}\n",
            "test Step Level Metrics: {'precision': 0.08108108108108109, 'recall': 0.3333333333333333, 'f1': 0.13043478260869565, 'accuracy': 0.5238095238095238, 'auc': np.float64(0.47703703703703704), 'pr_auc': tensor(0.0985)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 1, Train Loss: 1.006358, Test Loss: 1.063528, Precision: 0.078947, Recall: 0.428571, F1: 0.133333, AUC: 0.399638\n",
            "Train Epoch: 2, Progress: 496/497, Loss: 1.436808: 100% 497/497 [00:33<00:00, 15.04it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.48it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.34916201117318435, 'recall': 0.5319148936170213, 'f1': 0.42158516020236086, 'accuracy': 0.49632892804698975, 'auc': np.float64(0.5197309417040359), 'pr_auc': tensor(0.3473)}\n",
            "val Step Level Metrics: {'precision': 0.14814814814814814, 'recall': 0.5714285714285714, 'f1': 0.23529411764705882, 'accuracy': 0.6976744186046512, 'auc': np.float64(0.5768535262206148), 'pr_auc': tensor(0.1195)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:05<00:00, 16.34it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4054726368159204, 'recall': 0.6763485477178424, 'f1': 0.5069984447900466, 'accuracy': 0.5275707898658718, 'auc': np.float64(0.5685129788671234), 'pr_auc': tensor(0.3905)}\n",
            "test Step Level Metrics: {'precision': 0.10344827586206896, 'recall': 0.3333333333333333, 'f1': 0.15789473684210525, 'accuracy': 0.6190476190476191, 'auc': np.float64(0.44888888888888884), 'pr_auc': tensor(0.1059)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 2, Train Loss: 0.987411, Test Loss: 1.054689, Precision: 0.148148, Recall: 0.571429, F1: 0.235294, AUC: 0.576854\n",
            "Train Epoch: 3, Progress: 496/497, Loss: 0.969906: 100% 497/497 [00:32<00:00, 15.20it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.34it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.39919354838709675, 'recall': 0.42127659574468085, 'f1': 0.40993788819875776, 'accuracy': 0.5814977973568282, 'auc': np.float64(0.5730083007346627), 'pr_auc': tensor(0.3679)}\n",
            "val Step Level Metrics: {'precision': 0.03333333333333333, 'recall': 0.14285714285714285, 'f1': 0.05405405405405406, 'accuracy': 0.5930232558139535, 'auc': np.float64(0.4086799276672694), 'pr_auc': tensor(0.0745)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:05<00:00, 16.47it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.444, 'recall': 0.4605809128630705, 'f1': 0.45213849287169044, 'accuracy': 0.5991058122205664, 'auc': np.float64(0.5925890186239505), 'pr_auc': tensor(0.3982)}\n",
            "test Step Level Metrics: {'precision': 0.10714285714285714, 'recall': 0.3333333333333333, 'f1': 0.16216216216216217, 'accuracy': 0.6309523809523809, 'auc': np.float64(0.5614814814814815), 'pr_auc': tensor(0.1071)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 3, Train Loss: 1.003345, Test Loss: 1.056658, Precision: 0.033333, Recall: 0.142857, F1: 0.054054, AUC: 0.408680\n",
            "Train Epoch: 4, Progress: 496/497, Loss: 0.978371: 100% 497/497 [00:32<00:00, 15.20it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 18.30it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3778705636743215, 'recall': 0.7702127659574468, 'f1': 0.5070028011204482, 'accuracy': 0.4831130690161527, 'auc': np.float64(0.5716439271061922), 'pr_auc': tensor(0.3703)}\n",
            "val Step Level Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.7906976744186046, 'auc': np.float64(0.5786618444846292), 'pr_auc': tensor(0.0814)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:04<00:00, 17.25it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4074844074844075, 'recall': 0.8132780082987552, 'f1': 0.5429362880886427, 'accuracy': 0.5081967213114754, 'auc': np.float64(0.6173598378847823), 'pr_auc': tensor(0.3985)}\n",
            "test Step Level Metrics: {'precision': 0.05, 'recall': 0.2222222222222222, 'f1': 0.08163265306122448, 'accuracy': 0.4642857142857143, 'auc': np.float64(0.43407407407407406), 'pr_auc': tensor(0.0944)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 4, Train Loss: 0.942388, Test Loss: 1.016179, Precision: 0.000000, Recall: 0.000000, F1: 0.000000, AUC: 0.578662\n",
            "Train Epoch: 5, Progress: 496/497, Loss: 1.014432: 100% 497/497 [00:32<00:00, 15.09it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 18.70it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.40625, 'recall': 0.16595744680851063, 'f1': 0.23564954682779457, 'accuracy': 0.6284875183553598, 'auc': np.float64(0.5726361988359889), 'pr_auc': tensor(0.3552)}\n",
            "val Step Level Metrics: {'precision': 0.0625, 'recall': 0.14285714285714285, 'f1': 0.08695652173913043, 'accuracy': 0.7558139534883721, 'auc': np.float64(0.5443037974683544), 'pr_auc': tensor(0.0787)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:04<00:00, 17.07it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.5204081632653061, 'recall': 0.21161825726141079, 'f1': 0.3008849557522124, 'accuracy': 0.646795827123696, 'auc': np.float64(0.580054038405867), 'pr_auc': tensor(0.3933)}\n",
            "test Step Level Metrics: {'precision': 0.07142857142857142, 'recall': 0.1111111111111111, 'f1': 0.08695652173913043, 'accuracy': 0.75, 'auc': np.float64(0.4103703703703704), 'pr_auc': tensor(0.1032)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 5, Train Loss: 0.916851, Test Loss: 1.653488, Precision: 0.062500, Recall: 0.142857, F1: 0.086957, AUC: 0.544304\n",
            "Train Epoch: 6, Progress: 496/497, Loss: 1.598651: 100% 497/497 [00:33<00:00, 14.93it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.60it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.3931034482758621, 'recall': 0.2425531914893617, 'f1': 0.3, 'accuracy': 0.6093979441997063, 'auc': np.float64(0.5838087968705277), 'pr_auc': tensor(0.3567)}\n",
            "val Step Level Metrics: {'precision': 0.08333333333333333, 'recall': 0.2857142857142857, 'f1': 0.12903225806451613, 'accuracy': 0.686046511627907, 'auc': np.float64(0.6491862567811935), 'pr_auc': tensor(0.0819)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:04<00:00, 17.27it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4966887417218543, 'recall': 0.3112033195020747, 'f1': 0.3826530612244898, 'accuracy': 0.639344262295082, 'auc': np.float64(0.6052976937180353), 'pr_auc': tensor(0.4020)}\n",
            "test Step Level Metrics: {'precision': 0.10714285714285714, 'recall': 0.3333333333333333, 'f1': 0.16216216216216217, 'accuracy': 0.6309523809523809, 'auc': np.float64(0.4666666666666667), 'pr_auc': tensor(0.1071)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 6, Train Loss: 0.867033, Test Loss: 1.258470, Precision: 0.083333, Recall: 0.285714, F1: 0.129032, AUC: 0.649186\n",
            "Train Epoch: 7, Progress: 496/497, Loss: 0.219968: 100% 497/497 [00:33<00:00, 15.02it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.70it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.4189189189189189, 'recall': 0.39574468085106385, 'f1': 0.40700218818380746, 'accuracy': 0.6020558002936858, 'auc': np.float64(0.6173170498998187), 'pr_auc': tensor(0.3743)}\n",
            "val Step Level Metrics: {'precision': 0.06666666666666667, 'recall': 0.14285714285714285, 'f1': 0.09090909090909091, 'accuracy': 0.7674418604651163, 'auc': np.float64(0.6582278481012658), 'pr_auc': tensor(0.0793)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:05<00:00, 16.11it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4517543859649123, 'recall': 0.42738589211618255, 'f1': 0.43923240938166314, 'accuracy': 0.6080476900149031, 'auc': np.float64(0.5972305316993148), 'pr_auc': tensor(0.3987)}\n",
            "test Step Level Metrics: {'precision': 0.18518518518518517, 'recall': 0.5555555555555556, 'f1': 0.2777777777777778, 'accuracy': 0.6904761904761905, 'auc': np.float64(0.6711111111111111), 'pr_auc': tensor(0.1505)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 7, Train Loss: 0.827450, Test Loss: 1.233891, Precision: 0.066667, Recall: 0.142857, F1: 0.090909, AUC: 0.658228\n",
            "Train Epoch: 8, Progress: 496/497, Loss: 0.456037: 100% 497/497 [00:32<00:00, 15.12it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.69it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.4152542372881356, 'recall': 0.41702127659574467, 'f1': 0.416135881104034, 'accuracy': 0.5961820851688693, 'auc': np.float64(0.5930540978914226), 'pr_auc': tensor(0.3743)}\n",
            "val Step Level Metrics: {'precision': 0.07407407407407407, 'recall': 0.2857142857142857, 'f1': 0.11764705882352941, 'accuracy': 0.6511627906976745, 'auc': np.float64(0.5244122965641953), 'pr_auc': tensor(0.0793)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:05<00:00, 16.32it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.48828125, 'recall': 0.5186721991701245, 'f1': 0.5030181086519114, 'accuracy': 0.6318926974664679, 'auc': np.float64(0.6487600115796585), 'pr_auc': tensor(0.4261)}\n",
            "test Step Level Metrics: {'precision': 0.125, 'recall': 0.3333333333333333, 'f1': 0.18181818181818182, 'accuracy': 0.6785714285714286, 'auc': np.float64(0.642962962962963), 'pr_auc': tensor(0.1131)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 8, Train Loss: 0.766143, Test Loss: 1.131433, Precision: 0.074074, Recall: 0.285714, F1: 0.117647, AUC: 0.524412\n",
            "Train Epoch: 9, Progress: 496/497, Loss: 0.243598: 100% 497/497 [00:33<00:00, 15.05it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 18.03it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.4090909090909091, 'recall': 0.15319148936170213, 'f1': 0.22291021671826625, 'accuracy': 0.631424375917768, 'auc': np.float64(0.5679706134910791), 'pr_auc': tensor(0.3549)}\n",
            "val Step Level Metrics: {'precision': 0.1, 'recall': 0.2857142857142857, 'f1': 0.14814814814814814, 'accuracy': 0.7325581395348837, 'auc': np.float64(0.5768535262206148), 'pr_auc': tensor(0.0867)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:04<00:00, 17.08it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.475, 'recall': 0.15767634854771784, 'f1': 0.2367601246105919, 'accuracy': 0.6348733233979136, 'auc': np.float64(0.5854868281385699), 'pr_auc': tensor(0.3774)}\n",
            "test Step Level Metrics: {'precision': 0.1111111111111111, 'recall': 0.2222222222222222, 'f1': 0.14814814814814814, 'accuracy': 0.7261904761904762, 'auc': np.float64(0.4029629629629629), 'pr_auc': tensor(0.1080)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 9, Train Loss: 0.689494, Test Loss: 1.502643, Precision: 0.100000, Recall: 0.285714, F1: 0.148148, AUC: 0.576854\n",
            "Train Epoch: 10, Progress: 496/497, Loss: 0.106650: 100% 497/497 [00:33<00:00, 14.95it/s]\n",
            "val Progress: 681/86: 100% 86/86 [00:04<00:00, 19.06it/s]\n",
            "----------------------------------------------------------------\n",
            "val Sub Step Level Metrics: {'precision': 0.40086206896551724, 'recall': 0.39574468085106385, 'f1': 0.39828693790149894, 'accuracy': 0.5873715124816447, 'auc': np.float64(0.566777979200458), 'pr_auc': tensor(0.3672)}\n",
            "val Step Level Metrics: {'precision': 0.14814814814814814, 'recall': 0.5714285714285714, 'f1': 0.23529411764705882, 'accuracy': 0.6976744186046512, 'auc': np.float64(0.6943942133815552), 'pr_auc': tensor(0.1195)}\n",
            "----------------------------------------------------------------\n",
            "test Progress: 671/84: 100% 84/84 [00:04<00:00, 17.10it/s]\n",
            "----------------------------------------------------------------\n",
            "test Sub Step Level Metrics: {'precision': 0.4444444444444444, 'recall': 0.46473029045643155, 'f1': 0.4543610547667343, 'accuracy': 0.5991058122205664, 'auc': np.float64(0.6172440413007817), 'pr_auc': tensor(0.3988)}\n",
            "test Step Level Metrics: {'precision': 0.1, 'recall': 0.2222222222222222, 'f1': 0.13793103448275862, 'accuracy': 0.7023809523809523, 'auc': np.float64(0.5274074074074073), 'pr_auc': tensor(0.1056)}\n",
            "----------------------------------------------------------------\n",
            "Epoch: 10, Train Loss: 0.648947, Test Loss: 1.675570, Precision: 0.148148, Recall: 0.571429, F1: 0.235294, AUC: 0.694394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate LSTM model\n",
        "import os\n",
        "import glob\n",
        "os.chdir('/content/code')\n",
        "\n",
        "# Find the best checkpoint\n",
        "lstm_ckpts = glob.glob('checkpoints/error_recognition/LSTM/omnivore/*_best.pt')\n",
        "if not lstm_ckpts:\n",
        "    # If no _best.pt, find latest checkpoint\n",
        "    all_ckpts = sorted(glob.glob('checkpoints/error_recognition/LSTM/omnivore/*.pt'), key=os.path.getmtime)\n",
        "    if all_ckpts:\n",
        "        lstm_ckpt = all_ckpts[-1]  # Latest checkpoint\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No LSTM checkpoints found!\")\n",
        "else:\n",
        "    lstm_ckpt = lstm_ckpts[0]\n",
        "\n",
        "print(f\"Using checkpoint: {lstm_ckpt}\")\n",
        "\n",
        "# Evaluate on recordings split\n",
        "!python -m core.evaluate_error_types \\\n",
        "    --variant LSTM \\\n",
        "    --backbone omnivore \\\n",
        "    --split recordings \\\n",
        "    --ckpt \"{lstm_ckpt}\" \\\n",
        "    --threshold 0.4 \\\n",
        "    --save_csv"
      ],
      "metadata": {
        "id": "ugC2R1A1Jmp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64a1385-8ad9-4d8e-f2e5-c288bc2bb41c"
      },
      "id": "ugC2R1A1Jmp9",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using checkpoint: checkpoints/error_recognition/LSTM/omnivore/error_recognition_recordings_omnivore_LSTM_video_best.pt\n",
            "Using device: cuda\n",
            "Loaded checkpoint: checkpoints/error_recognition/LSTM/omnivore/error_recognition_recordings_omnivore_LSTM_video_best.pt\n",
            "Loaded annotations for error type analysis...\n",
            "Evaluating: 100% 671/671 [00:04<00:00, 158.53it/s]\n",
            "\n",
            "================================================================================\n",
            "ERROR TYPE ANALYSIS - LSTM (omnivore) - recordings split\n",
            "================================================================================\n",
            "\n",
            "OVERALL METRICS:\n",
            "----------------------------------------\n",
            "  Accuracy:  45.16%\n",
            "  Precision: 38.43%\n",
            "  Recall:    87.55%\n",
            "  F1 Score:  53.42%\n",
            "  AUC:       57.48%\n",
            "\n",
            "PER ERROR TYPE METRICS:\n",
            "--------------------------------------------------------------------------------\n",
            "Error Type                   Count      Acc     Prec   Recall       F1      AUC\n",
            "--------------------------------------------------------------------------------\n",
            "Technique Error                  0    0.00%    0.00%    0.00%    0.00%    0.00%\n",
            "Preparation Error                0    0.00%    0.00%    0.00%    0.00%    0.00%\n",
            "Temperature Error                0    0.00%    0.00%    0.00%    0.00%    0.00%\n",
            "Measurement Error                0    0.00%    0.00%    0.00%    0.00%    0.00%\n",
            "Timing Error                     0    0.00%    0.00%    0.00%    0.00%    0.00%\n",
            "================================================================================\n",
            "\n",
            "Results saved to: results/error_type_analysis/LSTM_omnivore_recordings_error_type_analysis.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all three baselines\n",
        "import os\n",
        "import glob\n",
        "os.chdir('/content/code')\n",
        "\n",
        "# Find checkpoints for all models\n",
        "def find_best_ckpt(pattern):\n",
        "    best = glob.glob(pattern.replace('*.pt', '*_best.pt'))\n",
        "    if best:\n",
        "        return best[0]\n",
        "    all_ckpts = sorted(glob.glob(pattern), key=os.path.getmtime)\n",
        "    return all_ckpts[-1] if all_ckpts else None\n",
        "\n",
        "mlp_ckpt = find_best_ckpt('checkpoints/error_recognition/MLP/omnivore/*.pt')\n",
        "transformer_ckpt = find_best_ckpt('checkpoints/error_recognition/Transformer/omnivore/*.pt')\n",
        "lstm_ckpt = find_best_ckpt('checkpoints/error_recognition/LSTM/omnivore/*.pt')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CHECKPOINT SEARCH RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"MLP: {mlp_ckpt if mlp_ckpt else 'âŒ Not found'}\")\n",
        "print(f\"Transformer: {transformer_ckpt if transformer_ckpt else 'âŒ Not found'}\")\n",
        "print(f\"LSTM: {lstm_ckpt if lstm_ckpt else 'âŒ Not found'}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Build command with only available checkpoints\n",
        "checkpoints = {}\n",
        "if mlp_ckpt and os.path.exists(mlp_ckpt):\n",
        "    checkpoints['MLP'] = mlp_ckpt\n",
        "if transformer_ckpt and os.path.exists(transformer_ckpt):\n",
        "    checkpoints['Transformer'] = transformer_ckpt\n",
        "if lstm_ckpt and os.path.exists(lstm_ckpt):\n",
        "    checkpoints['LSTM'] = lstm_ckpt\n",
        "\n",
        "if len(checkpoints) == 0:\n",
        "    print(\"\\nâŒ No checkpoints found! Please train models first.\")\n",
        "    print(\"   Available checkpoints will be compared automatically.\")\n",
        "elif len(checkpoints) == 1:\n",
        "    print(f\"\\nâš ï¸  Only {list(checkpoints.keys())[0]} checkpoint found.\")\n",
        "    print(\"   Need at least 2 models to compare. Train other models first.\")\n",
        "else:\n",
        "    print(f\"\\nâœ… Found {len(checkpoints)} checkpoints. Comparing...\")\n",
        "\n",
        "    # Build command dynamically using subprocess\n",
        "    import subprocess\n",
        "    cmd = [\"python\", \"compare_baselines.py\", \"--split\", \"recordings\", \"--backbone\", \"omnivore\"]\n",
        "    if 'MLP' in checkpoints:\n",
        "        cmd.extend([\"--mlp_ckpt\", checkpoints[\"MLP\"]])\n",
        "    if 'Transformer' in checkpoints:\n",
        "        cmd.extend([\"--transformer_ckpt\", checkpoints[\"Transformer\"]])\n",
        "    if 'LSTM' in checkpoints:\n",
        "        cmd.extend([\"--lstm_ckpt\", checkpoints[\"LSTM\"]])\n",
        "    cmd.append(\"--save_csv\")\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"Errors:\", result.stderr)"
      ],
      "metadata": {
        "id": "ongI9WvLJo7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f69c88-efca-4d45-c7d6-1e8ce3c09387"
      },
      "id": "ongI9WvLJo7A",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CHECKPOINT SEARCH RESULTS\n",
            "======================================================================\n",
            "MLP: checkpoints/error_recognition/MLP/omnivore/error_recognition_recordings_omnivore_MLP_video_best.pt\n",
            "Transformer: checkpoints/error_recognition/Transformer/omnivore/error_recognition_recordings_omnivore_Transformer_video_best.pt\n",
            "LSTM: checkpoints/error_recognition/LSTM/omnivore/error_recognition_recordings_omnivore_LSTM_video_best.pt\n",
            "======================================================================\n",
            "\n",
            "âœ… Found 3 checkpoints. Comparing...\n",
            "Using device: cuda\n",
            "\n",
            "ğŸ“Š Evaluating MLP...\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "\n",
            "ğŸ“Š Evaluating Transformer...\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "\n",
            "ğŸ“Š Evaluating LSTM...\n",
            "Loaded annotations...... \n",
            "Loading recording ids from recordings_combined_splits.json\n",
            "\n",
            "==========================================================================================\n",
            "BASELINE COMPARISON - RECORDINGS SPLIT\n",
            "==========================================================================================\n",
            "+-------------+------------+------------+-------------+----------+-------+-------+\n",
            "| Model       | Backbone   |   Accuracy |   Precision |   Recall |    F1 |   AUC |\n",
            "+=============+============+============+=============+==========+=======+=======+\n",
            "| MLP         | omnivore   |      44.26 |       38.51 |    92.53 | 54.39 | 60.7  |\n",
            "+-------------+------------+------------+-------------+----------+-------+-------+\n",
            "| Transformer | omnivore   |      42.62 |       37.14 |    86.31 | 51.94 | 52.11 |\n",
            "+-------------+------------+------------+-------------+----------+-------+-------+\n",
            "| LSTM        | omnivore   |      45.16 |       38.43 |    87.55 | 53.42 | 57.48 |\n",
            "+-------------+------------+------------+-------------+----------+-------+-------+\n",
            "==========================================================================================\n",
            "\n",
            "Results saved to: results/baseline_comparison.csv\n",
            "\n",
            "Errors: \n",
            "Evaluating:   0%|          | 0/671 [00:00<?, ?it/s]\n",
            "Evaluating:   0%|          | 2/671 [00:00<00:37, 17.92it/s]\n",
            "Evaluating:   4%|â–         | 26/671 [00:00<00:04, 138.94it/s]\n",
            "Evaluating:   8%|â–Š         | 51/671 [00:00<00:03, 185.80it/s]\n",
            "Evaluating:  11%|â–ˆâ–        | 76/671 [00:00<00:02, 207.11it/s]\n",
            "Evaluating:  14%|â–ˆâ–        | 97/671 [00:00<00:03, 164.76it/s]\n",
            "Evaluating:  17%|â–ˆâ–‹        | 115/671 [00:00<00:04, 126.72it/s]\n",
            "Evaluating:  20%|â–ˆâ–‰        | 132/671 [00:00<00:03, 135.53it/s]\n",
            "Evaluating:  22%|â–ˆâ–ˆâ–       | 148/671 [00:01<00:04, 120.33it/s]\n",
            "Evaluating:  24%|â–ˆâ–ˆâ–       | 162/671 [00:01<00:04, 113.20it/s]\n",
            "Evaluating:  26%|â–ˆâ–ˆâ–Œ       | 175/671 [00:01<00:04, 113.98it/s]\n",
            "Evaluating:  30%|â–ˆâ–ˆâ–‰       | 199/671 [00:01<00:03, 143.33it/s]\n",
            "Evaluating:  33%|â–ˆâ–ˆâ–ˆâ–      | 222/671 [00:01<00:02, 163.83it/s]\n",
            "Evaluating:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 240/671 [00:01<00:02, 160.47it/s]\n",
            "Evaluating:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 257/671 [00:01<00:02, 142.70it/s]\n",
            "Evaluating:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 278/671 [00:01<00:02, 158.25it/s]\n",
            "Evaluating:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 296/671 [00:02<00:02, 163.66it/s]\n",
            "Evaluating:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 316/671 [00:02<00:02, 173.02it/s]\n",
            "Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 337/671 [00:02<00:01, 181.30it/s]\n",
            "Evaluating:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 356/671 [00:02<00:02, 149.48it/s]\n",
            "Evaluating:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 374/671 [00:02<00:01, 155.64it/s]\n",
            "Evaluating:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 391/671 [00:02<00:02, 135.85it/s]\n",
            "Evaluating:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 406/671 [00:02<00:01, 138.25it/s]\n",
            "Evaluating:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 424/671 [00:02<00:01, 147.38it/s]\n",
            "Evaluating:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 441/671 [00:02<00:01, 151.71it/s]\n",
            "Evaluating:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 465/671 [00:03<00:01, 174.65it/s]\n",
            "Evaluating:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 486/671 [00:03<00:01, 184.33it/s]\n",
            "Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 505/671 [00:03<00:00, 183.00it/s]\n",
            "Evaluating:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 525/671 [00:03<00:00, 185.81it/s]\n",
            "Evaluating:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 546/671 [00:03<00:00, 191.77it/s]\n",
            "Evaluating:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 568/671 [00:03<00:00, 198.73it/s]\n",
            "Evaluating:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 591/671 [00:03<00:00, 205.90it/s]\n",
            "Evaluating:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 612/671 [00:03<00:00, 196.14it/s]\n",
            "Evaluating:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 639/671 [00:03<00:00, 216.75it/s]\n",
            "Evaluating:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 664/671 [00:04<00:00, 226.29it/s]\n",
            "                                                              \n",
            "\n",
            "Evaluating:   0%|          | 0/671 [00:00<?, ?it/s]\n",
            "Evaluating:   3%|â–         | 18/671 [00:00<00:03, 174.06it/s]\n",
            "Evaluating:   6%|â–Œ         | 40/671 [00:00<00:03, 200.32it/s]\n",
            "Evaluating:  11%|â–ˆ         | 72/671 [00:00<00:02, 244.61it/s]\n",
            "Evaluating:  14%|â–ˆâ–        | 97/671 [00:00<00:03, 172.05it/s]\n",
            "Evaluating:  17%|â–ˆâ–‹        | 117/671 [00:00<00:03, 141.09it/s]\n",
            "Evaluating:  20%|â–ˆâ–‰        | 133/671 [00:00<00:03, 143.28it/s]\n",
            "Evaluating:  22%|â–ˆâ–ˆâ–       | 149/671 [00:00<00:04, 128.67it/s]\n",
            "Evaluating:  24%|â–ˆâ–ˆâ–       | 163/671 [00:01<00:04, 121.64it/s]\n",
            "Evaluating:  26%|â–ˆâ–ˆâ–Œ       | 176/671 [00:01<00:04, 121.47it/s]\n",
            "Evaluating:  29%|â–ˆâ–ˆâ–‰       | 195/671 [00:01<00:03, 138.67it/s]\n",
            "Evaluating:  32%|â–ˆâ–ˆâ–ˆâ–      | 216/671 [00:01<00:02, 157.40it/s]\n",
            "Evaluating:  35%|â–ˆâ–ˆâ–ˆâ–      | 233/671 [00:01<00:02, 148.02it/s]\n",
            "Evaluating:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 249/671 [00:01<00:03, 136.55it/s]\n",
            "Evaluating:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 264/671 [00:01<00:03, 129.12it/s]\n",
            "Evaluating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 282/671 [00:01<00:02, 140.21it/s]\n",
            "Evaluating:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 297/671 [00:02<00:02, 142.71it/s]\n",
            "Evaluating:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 316/671 [00:02<00:02, 154.73it/s]\n",
            "Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 335/671 [00:02<00:02, 164.49it/s]\n",
            "Evaluating:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 352/671 [00:02<00:02, 135.85it/s]\n",
            "Evaluating:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 367/671 [00:02<00:02, 134.63it/s]\n",
            "Evaluating:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 382/671 [00:02<00:02, 132.54it/s]\n",
            "Evaluating:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 396/671 [00:02<00:02, 116.92it/s]\n",
            "Evaluating:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 415/671 [00:02<00:01, 134.27it/s]\n",
            "Evaluating:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 430/671 [00:03<00:01, 132.05it/s]\n",
            "Evaluating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 447/671 [00:03<00:01, 140.18it/s]\n",
            "Evaluating:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 470/671 [00:03<00:01, 163.04it/s]\n",
            "Evaluating:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 487/671 [00:03<00:01, 162.99it/s]\n",
            "Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 504/671 [00:03<00:01, 162.25it/s]\n",
            "Evaluating:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 521/671 [00:03<00:00, 162.34it/s]\n",
            "Evaluating:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 538/671 [00:03<00:00, 163.23it/s]\n",
            "Evaluating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 556/671 [00:03<00:00, 166.00it/s]\n",
            "Evaluating:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 577/671 [00:03<00:00, 177.30it/s]\n",
            "Evaluating:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 595/671 [00:03<00:00, 172.03it/s]\n",
            "Evaluating:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 613/671 [00:04<00:00, 167.11it/s]\n",
            "Evaluating:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 636/671 [00:04<00:00, 182.90it/s]\n",
            "Evaluating:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 658/671 [00:04<00:00, 193.02it/s]\n",
            "                                                              \n",
            "\n",
            "Evaluating:   0%|          | 0/671 [00:00<?, ?it/s]\n",
            "Evaluating:   4%|â–         | 24/671 [00:00<00:02, 233.33it/s]\n",
            "Evaluating:   7%|â–‹         | 49/671 [00:00<00:02, 241.08it/s]\n",
            "Evaluating:  11%|â–ˆâ–        | 76/671 [00:00<00:02, 251.96it/s]\n",
            "Evaluating:  15%|â–ˆâ–Œ        | 102/671 [00:00<00:03, 172.09it/s]\n",
            "Evaluating:  18%|â–ˆâ–Š        | 122/671 [00:00<00:03, 154.61it/s]\n",
            "Evaluating:  21%|â–ˆâ–ˆ        | 140/671 [00:00<00:03, 145.39it/s]\n",
            "Evaluating:  23%|â–ˆâ–ˆâ–       | 156/671 [00:00<00:03, 133.09it/s]\n",
            "Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 171/671 [00:01<00:03, 127.84it/s]\n",
            "Evaluating:  28%|â–ˆâ–ˆâ–Š       | 191/671 [00:01<00:03, 144.91it/s]\n",
            "Evaluating:  32%|â–ˆâ–ˆâ–ˆâ–      | 214/671 [00:01<00:02, 165.51it/s]\n",
            "Evaluating:  35%|â–ˆâ–ˆâ–ˆâ–      | 232/671 [00:01<00:02, 158.22it/s]\n",
            "Evaluating:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 249/671 [00:01<00:02, 146.21it/s]\n",
            "Evaluating:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 265/671 [00:01<00:02, 137.87it/s]\n",
            "Evaluating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 284/671 [00:01<00:02, 150.29it/s]\n",
            "Evaluating:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 302/671 [00:01<00:02, 157.02it/s]\n",
            "Evaluating:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 324/671 [00:02<00:02, 173.14it/s]\n",
            "Evaluating:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 342/671 [00:02<00:02, 157.91it/s]\n",
            "Evaluating:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 359/671 [00:02<00:02, 137.39it/s]\n",
            "Evaluating:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 375/671 [00:02<00:02, 142.83it/s]\n",
            "Evaluating:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 390/671 [00:02<00:02, 125.74it/s]\n",
            "Evaluating:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 404/671 [00:02<00:02, 120.61it/s]\n",
            "Evaluating:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 419/671 [00:02<00:01, 126.16it/s]\n",
            "Evaluating:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 433/671 [00:02<00:01, 122.78it/s]\n",
            "Evaluating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 450/671 [00:03<00:01, 134.13it/s]\n",
            "Evaluating:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 473/671 [00:03<00:01, 159.04it/s]\n",
            "Evaluating:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 490/671 [00:03<00:01, 155.59it/s]\n",
            "Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 506/671 [00:03<00:01, 151.93it/s]\n",
            "Evaluating:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 523/671 [00:03<00:00, 154.58it/s]\n",
            "Evaluating:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 541/671 [00:03<00:00, 159.35it/s]\n",
            "Evaluating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 558/671 [00:03<00:00, 158.89it/s]\n",
            "Evaluating:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 579/671 [00:03<00:00, 171.30it/s]\n",
            "Evaluating:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 597/671 [00:03<00:00, 156.61it/s]\n",
            "Evaluating:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 613/671 [00:04<00:00, 154.84it/s]\n",
            "Evaluating:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 635/671 [00:04<00:00, 171.05it/s]\n",
            "Evaluating:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 658/671 [00:04<00:00, 185.52it/s]\n",
            "                                                              \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Show baseline comparison\n",
        "comparison_path = 'results/baseline_comparison.csv'\n",
        "if os.path.exists(comparison_path):\n",
        "    df = pd.read_csv(comparison_path)\n",
        "    print(\"=\" * 70)\n",
        "    print(\"BASELINE COMPARISON RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(df.to_string(index=False))\n",
        "else:\n",
        "    print(f\"Results file not found: {comparison_path}\")\n",
        "\n",
        "# Show error type analysis\n",
        "error_type_path = 'results/error_type_analysis/LSTM_omnivore_recordings_error_type_analysis.csv'\n",
        "if os.path.exists(error_type_path):\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"LSTM ERROR TYPE ANALYSIS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # The CSV has two sections, so read it manually\n",
        "    try:\n",
        "        with open(error_type_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Find where \"Per Error Type Metrics\" section starts\n",
        "        per_error_start = None\n",
        "        for i, line in enumerate(lines):\n",
        "            if 'Per Error Type Metrics' in line:\n",
        "                per_error_start = i + 1\n",
        "                break\n",
        "\n",
        "        if per_error_start:\n",
        "            # Read from the per-error-type section (skip header line)\n",
        "            df_errors = pd.read_csv(error_type_path, skiprows=per_error_start + 1)\n",
        "            print(df_errors.to_string(index=False))\n",
        "        else:\n",
        "            # Fallback: display raw content\n",
        "            print(\"\".join(lines))\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV: {e}\")\n",
        "        # Fallback: display raw content\n",
        "        with open(error_type_path, 'r') as f:\n",
        "            print(f.read())\n",
        "else:\n",
        "    print(f\"\\nError type analysis not found: {error_type_path}\")\n"
      ],
      "metadata": {
        "id": "PkK7MZSXJrMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efada1ef-ca88-4e1a-ce3d-092d7b537f6e"
      },
      "id": "PkK7MZSXJrMH",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "BASELINE COMPARISON RESULTS\n",
            "======================================================================\n",
            "      Model Backbone      Split  Accuracy  Precision  Recall    F1   AUC\n",
            "        MLP omnivore recordings     44.26      38.51   92.53 54.39 60.70\n",
            "Transformer omnivore recordings     42.62      37.14   86.31 51.94 52.11\n",
            "       LSTM omnivore recordings     45.16      38.43   87.55 53.42 57.48\n",
            "\n",
            "======================================================================\n",
            "LSTM ERROR TYPE ANALYSIS\n",
            "======================================================================\n",
            "  Technique Error  0  0.00  0.00.1  0.00.2  0.00.3  0.00.4\n",
            "Preparation Error  0   0.0     0.0     0.0     0.0     0.0\n",
            "Temperature Error  0   0.0     0.0     0.0     0.0     0.0\n",
            "Measurement Error  0   0.0     0.0     0.0     0.0     0.0\n",
            "     Timing Error  0   0.0     0.0     0.0     0.0     0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}